\section{Metric Trees and Spill Trees}

\vspace{5 mm}
\noindent
Please note that for this section we will be explaining how hybrid spill 
trees operate, so that we can then implement them in our final algorithm. 
As such, we will be paraphrasing and borrowing heavily from  \textit{``
An Investigation of Practical Approximate Nearest Neighbor Algorithms''},
which is cited below.  Any fine details below originate from [5].

\vspace{5 mm}
\noindent
As mentioned earlier in the report, performing K nearest neighbor search for 
data geometry applications is computationally infeasible for large data sets. 
If we were to apply a modified version of the serial algorithm mentioned in the 
prior section, our time complexity would be $O(N^{2} P)$. For a modified 
distributed classificaiton algorithm, our time complexity would be 
$O(P \ceil*{\frac{N^{2}}{S}}$ assuming $N < P \ceil*{\frac{N^{2}}{S}}$. 
\textbf{THIS DOESN'T MAKE SENSE, FIX}
To alleviate this problem, we must approximate the solution. There are a 
variety of approximate solution techniques for K nearest neighbor search. We 
will focus on using hybrid spill trees and metric trees as our primary data 
structure.

\vspace{5 mm}
\noindent
Spill trees are specialized data storage constructs that are designed to 
efficiently organize a set of multidimensional points.  Spill trees operate by 
constructing a binary tree. The children in a full spill tree are a sub-set of 
the original data that empirically have the property of being close to one 
another. In other words, the spill tree is a way to look up data in which we 
can determine which data point is close to other observations.

\vspace{5 mm}
\noindent
Each parent node stores a classification method for whether a data point should 
go ``left'' or ``right'' along the node split. The classification method is 
done on whether the data point we wish to classify appears on either the left 
or right side of a boundary drawn through the data set (we'll talk about this 
boundary later in this report). The idea is that this boundary is constructed 
such that after a data point traverses the whole tree, it will have a high 
likelihood of ending up in a subset of data that is close to that point.

\vspace{5 mm}
\noindent
\textbf{Spill Tree - Algorithm}

\vspace{5 mm}
\noindent
The method for constructing a spill tree is as follows:

\begin{itemize}
  \item Starting at the root of the tree, we consider our whole data set. At 
  each parent node, say $v$, we consider the subset of data that abide by the 
  decision bound created in the previous parent nodes.
  \item For each parent, we define two pivot nodes $p.lc$ and $p.rc$ such that 
  $p.lc$ and $p.rc$ have the maximum distance between them compared to all 
  other data points.
  \item We construct a hyperplane between $p.lc$ and $p.rc$ such that the line 
  between the two points is normal to the hyperplane and every point on the 
  hyperplane is equidistant from $p.lc$ and $p.rc$.
  \item Define $\tau$ as the overlap size, with $0 \le \tau < \infty$. $\tau$ 
  is a tuning parameter in our construction of the spill tree. We use $\tau$ 
  to construct two additional planes that are parallel to our initial 
  hyperplane and are distance $\tau$ away from this initial boundary hyperplane.
  \item We define the two new hyperplane boundaries as follows: the hyperplane 
  that is closest to $p.lc$ is $\tau.lc$ and the other closer to $p.rc$ is 
  $\tau.rc$.
  \item We finally split the data at node $v$ based on the rule that if the 
  data point is to the left of $\tau.rc$, we send it to the right child and if 
  it is to the right of $\tau.lc$ we send it to the left child. If a data point 
  satisfies both conditions, it is sent to both the right and left child.
  \item We keep splitting the data until the data size in each node hits a 
  specified threshold.
\end{itemize}

\vspace{1 mm}
\noindent
Notice that the use of the $\tau$ parameter allows for data to be duplicated if 
it appears within $\tau$ of the initial boundary split. The use of this 
parameter is the defining feature of a spill tree. Spill trees that set 
$\tau = 0$ are called metric trees. The purpose of using $\tau$ is to get 
increased accuracy that we pick a subset of data in which points near the 
separation boundary is actually closest to. The larger the tau, the more 
accurate the splits, but also the more duplications of data we make and the 
slower the process.

\vspace{5 mm}
\noindent
The pseudo code for implementation of our algorithm $SpillTree$ is:

\newpage

\begin{algorithm}[ht!]
%-------------------------------Header------------------------------------------
\DontPrintSemicolon
\KwData{$X = N \times P + 1$ matrix of data, with each data $x_{i}$ having ID $i$.\\ 
\hspace{50pt} Have column $P + 1$ contain the class of $x_{i}$ \\
\hspace{29pt} $U = $ a specified threshold upper bound to stop splitting\\
\hspace{29pt} $\tau = $ our buffer parameter\\
\hspace{29pt} $D = N \times N $ matrix of all distances between $x_{i}$'s. \\
\hspace{50pt} Let $D[i, j] = $ distance between $x_{i}$ and $x_{j}$. \\
\hspace{29pt} $T_{acc} = $ our accumulated tree. Initalized to just a root node. \\
\hspace{29pt} $n_{curr} = $ a pointer to current node of $T_{acc}$ we are considdering.}
\KwResult{$T = $ our spill tree}
%-------------------------------Body--------------------------------------------
\Begin{
    If $D$ is empty (first call) compute $D$ with $X$ \;
    \If{$|X| < U$}{
        return $T_{acc}$ \;
    }
    \Else{
        $d_{max} \leftarrow max(D[i, j])$ \;
        $x_{i-max}$, $x_{j-max}$ $\leftarrow x_{i}$, $x_{j}$ s.t. 
        $dist(x_{i}, x_{j}) == d_{max}$ \;
        $plane \leftarrow$ separting plane midway and equidistant \;
            \hspace{10pt} between $x_{i-max}$, $x_{j-max}$ \;
        $plane_{-\tau}$, $plane_{+\tau}$ $\leftarrow$ planes parallel to $plane$ \;
            \hspace{10pt} and $+/- \tau$ distance from $plane$ \:
        $D_{r}$, $D_{l}$ $\leftarrow D$ \;
        $X_{r}$, $X_{l}$ $\leftarrow X$ \;
        \For{$x_{i} \in X$}{
            \If{$x_{i}$ is to the left of $plane_{+\tau}$ and not to the right of $plane_{-\tau}$}{
                drop $i$th row and column from $D_{r}$ and $X_{r}$ \;
            }
            \Else{IF: $x_{i}$ is to the right of $plane_{-\tau}$ and not to the \; 
                   \hspace{10pt} left of $plane_{+\tau}$ \;
                drop the $i$th row and column from $D_{l}$ and $X_{l}$ \;
            }
        }
        create two new nodes $n_{curr.l}$ and $n_{curr.r}$ in $T_{acc}$ \;
        create two directional edges from $n_{curr}$ to $n_{curr.l}$ and $n_{curr.r}$ \;
        assign split criteria to $n_{curr}$ based on $plane_{-\tau}$ and $plan_{+\tau}$
        return: $SpillTree(X_{r}, U, \tau, D_{r}, T_{acc}, n_{curr.r}) + $\; 
        \hspace{10pt} $SpillTree(X_{l}, U, \tau, D_{l}, T_{acc}, n_{curr.l})$
    }
}
\caption{Spill Tree\label{ST1}}
\end{algorithm}

\vspace{5 mm}
\noindent
\textbf{Spill Tree - Analysis}

\vspace{5 mm}
\noindent
We will now analyize the time complexity for constructing a spill tree. First, 
note that the complexity of constructing a tree depends on the parameters that 
you use to construct the tree and your underlying data. Exact runtime will 
vary between use of data sets. For example, closely clustered data and large 
$\tau$, we duplicate a lot of data, which will cause us to create a deeper tree 
with a longer termination time. We will mainly focus on the time complexity 
that will be independent of your data.

\vspace{5 mm}
\noindent
We also note that this is a recursive algorithm, so when we talk about 
datasize, we mean the size of the data within the current recursive step.

\begin{itemize}
\item Constructing $D$ for the first time will be $O(N^{2} P)$ because we need 
to create a distance for each pair of points in $X$. Consequently passing and 
computing $D_{r}$ and $D_{l}$ will not cost much of anything except dropping a 
pointer to the row and column of data omitted in the recurrsive call.
\item Finding the maximum distance accross all pairwise points will be 
$O(N^{2})$
\item Constructing the split criteria for the current node will be $O(P)$, 
which corresponds to constructing a plane of $P$ dimensions.
\item Classifying each $x_{i}$ to the right and/or left split is $O(N P)$, 
corresponding to iterating through each point and evaluating which side of the 
hyperlane it lies on.
\item Dropping columns and rows of $D_{r}$, $D_{l}$, $X_{r}$, and $X_{l}$ are 
all $O(1)$ since it corresponds to just dropping pointers.
\item If we store $T$ as an adjacency list with pointers to the subset of data 
sets, adding completely new nodes and edges corresponds to just adding new rows, 
each with two pointers. This is a $O(1)$ opperation.
\end{itemize}

\vspace{5 mm}
\noindent
The above has an inital cost of $O(N^{2} P)$ outside of the recurssive calls 
associated with the initial construction of our $D$ matrix. Within our 
recurssive calls, the dominating opperation is $O(N^{2})$. We then can 
construct the following recurrsive relationship: $T(N) = T(f(N)) + N^{2}$, 
where $f(N)$ dictates how quickly our data is being depelted. The basecase for 
this recurrsive relationship is for $N < U$ and is $O(1)$.

\vspace{5 mm}
\noindent
Bounding $f(N)$ requires us to analyze our data structure and some of the 
parameters that we use to construct our spill tree (namely $\tau$). In fact, 
some of our choices of $\tau$ could possibly cause non-termination. For 
example, consider our selction of $\tau > max(D)$. At each step, we would be 
sending our data to both the left and right split each time. We would never 
reach our threshold $U$ and thus would never terminate.

\newpage
